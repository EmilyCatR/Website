---
title: "The Domino(s) Effect: Pizza Stats"
author: "Emily Reed"
date: "9/30/2020"
output:
  html_document:
    theme: journal
    toc: true
    toc_float:
      collapsed: false
      
      
---

---

#Introduction and Setup

<br>

<center>

![Source: media.giphy](https://media.giphy.com/media/9fuvOqZ8tbZOU/giphy.gif)

</center>

<br>

For the past several months, I have been working at a pizza place as a delivery driver. This dataset "pizza_data.csv" is data I have collected over the past few weeks. The data includes 9 different variables described below. 
<br>

> ###Variables
> 1. Date: The date of the pizza delivery
> 2. area: The section location of the delivery. Sections 1-16 and "MAIN" are designated by the store 
> 3. apartment_or_house: Designates whether the delivery was to a house or apartment
> 4. street_name: name or address of pizza delivery location
> 5. time: time that the order left the store
> 6. total: total cost of pizza order, without the tip
> 7. tip_method: How the customer tipped the driver, with three options of "pre_paid", "write_in" (customer signed receipt), and "cash_order"(customer did not pre-pay for entire order, instead paid with cash + tip at door)
> 8. hours_worked: The number of hours worked in that shift for that day
> 9. position_worked: The title of the position worked for that shift. Options include "Rush"(usually the shortest shift, starting anywhere from 4-6pm and ending anywhere from 6~9pm), "Late" (usually begins around 5-6pm, and ends around 9-11pm), and "Close" (usually begins around 5-6pm, ends around 1-2am)

<br>
There are 282 delivery observations over 20 shifts. I typically work rush or late shifts, but occasionally close. For this reason, there are more days that are "rush" or "late" than "close," (a total of 5 days for close).


```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, fig.align = "center", warning = F, message = F, tidy=T, tidy.opts=list(width.cutoff=50))
library(ggplot2)
library(tidyverse)
library(sandwich) 
library(lmtest) 
library(GGally)
library(plotROC) 
library(devtools)
library(mvtnorm)
library(gridExtra)
library(rstatix)

```
<br>
```{r}
setwd("/Users/emilyreed/Desktop/Website/content")
pizza <- read.csv("pizza_data.csv") 
glimpse(pizza)
```
<br>

I wanted to look at tips as a percentage rather than just an amount, so I created a new variable called "tip_perc" to see the percentage of tip compared to the whole total.
```{r}
pizza %>% mutate(tip=as.numeric(tip)) %>%  mutate(tip_perc=((tip*100)/total)) %>%  filter(tip_perc!=Inf) -> pizza
```

<br>

I also wanted to see how much money I made in tips per day as a rate per hour:
```{r}
#first making rate a new variable
pizza %>% 
  group_by(Date) %>% 
  filter(!is.na(tip)) %>% 
  filter(!is.na(total)) %>% 
  mutate(total_tips=sum(tip)) %>% 
  mutate(rate=(total_tips/hours_worked))->pizza2
  
#now displaying each rate in descending order
pizza %>% 
  group_by(Date) %>% 
  filter(!is.na(tip)) %>% 
  filter(!is.na(total)) %>% 
  mutate(total_tips=sum(tip)) %>% 
  mutate(rate=(total_tips/hours_worked)) %>% 
  summarize(rate=unique(rate)) %>% 
  arrange(desc(rate))

#how many deliveries did I take each day and how much money did I earn in tips?
pizza %>% group_by(Date) %>% filter(!is.na(tip)) %>%  summarize(deliveries=n(),tip_total=sum(tip)) %>% arrange(desc(deliveries))
```


---

#MANOVA

Alright, for the MANOVA I wanted to see if rate of tips per hour and tip percentage differed significantly by the position I worked. Since all other numeric variables were used in the creation of tip_perc and rate, I decided to omit them and just focus on the two listed above.

* Hypotheses:
    + H0: for each position worked (rush, late, close), the means for all groups (rate and tip_perc) are equal
    + Ha: for at least one position, at least 1 group (rate and/or tip_perc) mean differs.
    
```{r, fig.width=5, fig.height=5}
#Running the MANOVA
pizza2 %>%  na.omit -> pizza_no_NAs
man1 <- manova(cbind(rate,tip_perc) ~ position_worked, data=pizza_no_NAs)
summary(man1) #significant!!!!!!!

summary.aov(man1) #shows that rate is significant, not tip percentage with position worked

#which position?
pairwise.t.test(pizza_no_NAs$rate,pizza_no_NAs$position_worked, p.adj="none") 


#probability of making a type 1 error
Pr_type1error=1-.95^5
Pr_type1error

#adjusted significance level, still significant
a= .05/5
```
<br>
Five statistical tests were performed. The probability of making a type 1 error was 22.6%, so that also must be taken in to consideration. To account for this, the adjusted significance level was calculated to be .01. Using this number, late and close are significantly different in rate per hour (p value<.01), as well as rush and close (p value<.01). However, rush and late are not significantly different from each other in rate or tip_perc (p value>.01).
<br>

###Checking Assumptions
```{r}
group <- pizza_no_NAs$position_worked 
DVs <- pizza_no_NAs %>%ungroup() %>%  select(rate,tip_perc)

#Test multivariate normality for each group
sapply(split(DVs,group), mshapiro_test)

#check for mulitvariate normality via graph
ggplot(pizza_no_NAs, aes(x = rate, y = tip_perc)) +
  geom_point(alpha = .5) + 
  geom_density2d(aes(color=position_worked)) + 
  facet_wrap(~position_worked)

pizza_no_NAs %>% relocate(tip_perc, .after = total_tips)->pizza_no_NAs

#check for homogenity of covariances (for fun, even though multivariate normality is violated)
#Box's M test
box_m(DVs, group)

#View covariance matrices for each group
lapply(split(DVs,group), cov)
```
> ###MANOVA Assumptions:
    + Random Samples: *All of our deliveries are randomly assigned to each driver.*  
    + Multivariate Normality: *P values of multivariate test are p<.05, meaning the null assumption that normality is met is rejected. Graphs  also indicate normality is violated.*
    + Homogeneity of within-group covariance matrices: *P-value<.05 for mox M's test, meaning homogenity assumption is violated. The matrices look very different*
    + Linear relationships among DVs: *nope. higher tip_perc for one delivery does not mean overall rate for the day will be higher*
    + No extreme univariate or multivariate outliers: *there are some large outliers in tip_perc* 
    + No multicollinearity (i.e., DVs should not be too correlated): *rate and tip_perc should be different enough* 

<br>

Overall, the data does not meet the assumptions for a valid MANOVA to be possible. 

<br>

---

#Randomization Test
<br>
I wanted to see if housing type (aka apartment or house) was significantly related to tip percentage.

* Hypotheses:
    + H0: housing type (apartment of house) is not significantly related to tip percentage
    + Ha: housing type (apartment of house) is significantly related with tip percentage
    
```{r}
#Finding average percentaged tipped in apartments and houses
pizza_no_NAs%>%
  group_by(apartment_or_house)%>%
  summarize(means= mean(tip_perc))

#scaling tip perc
pizza_no_NAs %>% mutate_if(is.numeric, scale)->pizza_scale

#Finding the observed difference in means
pizza_scale%>%
  group_by(apartment_or_house)%>%
  summarize(means= mean(tip_perc))%>%
  summarize(mean_diff=diff(means)) 
```
<br>

On average, 'houses' tipped 20.24% of the total price, while apartments tipped 16.25% on average. Houses tipped ~4% more than apartments, based on total price of the order. Using the scaled data, the mean difference between housing type was .1614303, which will be used to calculate the two tailed p-value.

<br>

```{r}
#Randomization test. Scrambling houses and apartments and their tip percentages

set.seed(12)
rand_dist<-vector() 

for(i in 1:5000){
new<-data.frame(tip_perc=sample(pizza_scale$tip_perc), apartment_or_house=pizza_no_NAs$apartment_or_house) 
rand_dist[i]<-mean(new[new$apartment_or_house=="H",]$tip_perc)-   
              mean(new[new$apartment_or_house=="A",]$tip_perc)}


#finding the two tailed p value:
mean(rand_dist>0.1614303	 | rand_dist< -0.1614303) #fail to reject H0, there is no significant difference between apartment and house tip percentages

```
The two tailed p-value=.2302 (pvalue>.05), so we fail to reject the null hypothesis. There is no significant difference in tip percentage between houses and apartments based off their total order amount.

###Generating histograms 
<br>

```{r,fig.width=15, fig.height= 5, fig.align="center"}
#histogram for observed tip percentages for apartment vs houses
plot1 <- ggplot(pizza_scale, aes(x=tip_perc,fill=apartment_or_house))+
  geom_histogram(bins=7)+
  facet_wrap(~apartment_or_house)+
  ggtitle("Observed Values")

#histogram for random tip percentages for apartment vs houses
plot2 <- ggplot(new, aes(x=tip_perc,fill=apartment_or_house))+
  geom_histogram(bins=7)+
  facet_wrap(~apartment_or_house)+
  ggtitle("Randomization Test")

grid.arrange(plot1,plot2, ncol=2, top ="Observed vs Randomization tip percentages")
```

```{r}
#visualize test stat

{hist(rand_dist,main="",ylab=""); abline(v = c(-0.1614303	, 0.1614303),col="red")}

```

The histogram depicts the distance of means in the random data set (created by scrambling the original data), as well as the original observed difference in means (red vertical lines). Most of the random data is within the original data observed difference of means. There is lots of data that falls beyond the observed difference (reflected in our large calculated p-value of .2302).

---

#Linear Regression

<br>

I wanted to see if I could predict tip percentage from area and time. Due to the fact that both 'area' and 'time' had so many values, I created new variables to hopefully succinctly describe the data. For 'area' I created a new variable called "new_area_class" based on the average cost of the houses/apartments, which has four variables (instead of 17) of "apartments", "lower", "middle", and "higher". I also created a new variable from 'time' called "time_group", which is chunked by two-hour intervals. The three possible values for time_group are "early rush" (4-6pm), "late_rush" (6-8pm), and "night"(8pm-1am).

*note: I will not be centering tip_percentage because it is possible to receive a 0% tip, and therefore an understandable intercept.

* Hypotheses:
    + H01: controlling for area group, time doesn't explain variation in percent tip
    + H02 controlling for time, area group does not explain in tip percent

```{r}
#creating new variable of new area class to group together average housing costs 
pizza2 %>% filter(!is.na(area)) %>% filter(!is.na(tip_perc)) %>% 
  mutate(new_area_class= recode(area, "13" = "lower", "14" = "lower", "1" = "lower", "MAIN" ="apartments" ,"15"= "apartments", "4"="middle", "11"="middle","2"="middle","9"="middle","12"="middle", "10"="middle", "6"="higher",  "7"="higher","5"="higher","8"="higher","3"="higher", "16"= "higher")) -> pizza_new_area

#see how many observations are in each area
pizza_new_area %>% group_by(new_area_class) %>% summarize(n())

#average tip percentage based off of new area classes
pizza_new_area %>% group_by(new_area_class) %>% summarize(mean(tip_perc))

#creating new variable of time_group
pizza_new_area %>%
  filter(!is.na(time))  %>% 
  mutate(time2=str_replace(time, pattern=":", replacement= ".")) %>%  
  mutate(time2=as.numeric(time2)) %>% 
  mutate(time_group=(case_when(time2 >4 & time2<=6 ~ "early_rush",
                                                                                                                                                   time2 >6 & time2<=8 ~ "late_rush",
                                                                                                                                                   time2 >8   ~ "night" ))) ->pizza_new_area


#regression for tip_perc for tip percentage based on area groups and time of delivery
pizza_new_area <- pizza_new_area %>% filter(tip_perc!=Inf)
fit <- lm(tip_perc ~ new_area_class*time_group, data=pizza_new_area)
summary(fit)

```
<br>
Looking at the results from the linear regression, there does not seem to be any areas or time groups that are significantly different in tip percentage. The intercept indicates that "apartment areas" during early rush tip an average of 15.6662%. Analyzing the coefficent of new_area_classhigher, controlling for time group, the higher class tips an average .76% higher more compared to the "apartment area". What is very interesting is that, when controlling for time, the 'lower' and 'middle' class area tips higher on average than than 'higher' class area does. However, when time is a factor, tip percentage in lower class areas is shown to decrease in the night group and the rush group.

<br>

###Plot the regression
```{r}
#plotting the regression
pizza_new_area %>% 
  ggplot(aes(new_area_class,tip_perc,color=time_group))+
  geom_point()+
  geom_smooth(method="lm", se=F)+
  geom_jitter()
```

###Checking assumptions
```{r}
#checking for linearity
plot(fit, 1) #line is essentially horizontal, indicating linearity, not overall great

#checking for normality
resids<-fit$residuals
fitvals<-fit$fitted.values
par(mfrow=c(1,2)); hist(resids); qqnorm(resids); qqline(resids, col='red') #looks mostly normal, but a few outliers (high tip_perc) are disturbing the normality

#checking for homoskedasticity
bptest(fit) #pvalue>.05, so fail to reject the null hypothesis, homoskedasticity is met

#using robust standard errors on original fit object:
coeftest(fit, vcov = vcovHC(fit))

#how much variation is explained in the model?
summary(fit)$r.sq #this is a horrible model oh my

```
<br>
Even after using robust stanndard errors on the data, there is nothing too significant about a certain time group or area class. The coefficents stay the same. The model does an abysmal job of explaining the proportion of variation in the dataset, only about 4.2% is explained using Multiple R squared (ouch)


---

#Bootstrapped Standard Errors
<br>

```{r}
#sampling rows with replacement
boot_dat<- sample_frac(pizza_new_area, replace=T)

samp_distn<-replicate(5000, {
  boot_dat <- sample_frac(pizza_new_area, replace=T)
  fit <- lm(tip_perc~ new_area_class*time_group, data=boot_dat)
  coef(fit) 
}) 
 
## Estimated/boostrap SEs
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)

#CIs
samp_distn %>% t %>% as.data.frame %>% na.omit() %>% pivot_longer(1:12) %>% group_by(name) %>%
summarize(lower=quantile(value,.025), upper=quantile(value,.975))



```
<br>
Using bootstrapped standard errrors and a 95% CI greatly changed the intercept compared to using robust standard errors. Using this technique, the average tip percentage an "apartment" area during early rush is 1.09 standard deviations away from the mean, which the average percentage for this group is between 13.38% and 17.66% (using a 95% confidence interval). The higher class area during early rush tips anywhere between 10.837% and 21.79% using a 95% CI. The widest range group and time for tip_perc is in the area "middle" and time "night", with a 95% CI between 3.11% and 61.09%.

---

#Logistic Regression Model #1
<br>
Similar concept here. I wanted to see if I could predict housing type from percentage tipped and time (hour:minute, rather than time group) of delivery

```{r}
#predict house type from perc_tip and time? OR predict tip method from perc_tip and time
pizza_fit <- pizza_new_area %>% mutate(y=ifelse(apartment_or_house=="H",1,0)) %>% ungroup()

#finding average time of deliveries
pizza_fit %>% summarize(mean(time2))

#mean center time, since time is never 0
pizza_fit$time2<- pizza_fit$time2 - mean(pizza_fit$time2)


#running logistic regression 
fit3 <- glm(y~tip_perc+time2, data=pizza_fit, family=binomial(link="logit"))

coeftest(fit3)
exp(coef(fit3))

Pr_of_house_mean_time=1.4517/(1+1.4517)

#average tip percentage from houses vs apartment
pizza_new_area %>% group_by(apartment_or_house) %>% summarize(mean(tip_perc))
```
<br>
Predicted odds of delivering to a House when mean time of deliveries (7:18 pm) and tip percentage is zero is 1.4517, or a probability of 59.21%. Controlling for time, for every 1 unit increase in tip percentage, odds of delivering to a House go up by a factor of 1.0157. For every 1 minute increase in time, the odds of delivering to a house increase by a factor of .7930.
<br>
```{r}
#confusion matrix
pizza_fit$prob <- predict(fit3,type="response")
pizza_fit$predicted <- ifelse(pizza_fit$prob>.5,"House","Apartment")
table(truth=pizza_fit$apartment_or_house, prediction=pizza_fit$predicted)%>%addmargins

#for (Accuracy, Sensitivity, Specificity, Precision, AUC)
class_diag<-function(probs,truth){
  
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  prediction<-ifelse(probs>.5,1,0)
  acc=mean(truth==prediction)
  sens=mean(prediction[truth==1]==1)
  spec=mean(prediction[truth==0]==0)
  ppv=mean(truth[prediction==1]==1)
  f1=2*(sens*ppv)/(sens+ppv)
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

#finding accuracy, sensitivity (TPR), specificity (TNR), precision
class_diag(pizza_fit$prob, pizza_fit$y)

#density plot of the log-odds (logit)
pizza_fit$logit<-predict(fit3)
pizza_fit %>% ggplot(aes(logit, fill=apartment_or_house))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2)


#ROC plot
ROCplot<-ggplot(pizza_fit)+geom_roc(aes(d=y,m=prob), n.cuts=0) 
ROCplot

#AUC width
calc_auc(ROCplot)

```
<br>
The accuracy of the model predicting housing type from tip percentage from time is 67.37%. The sensitivity, or the true positive rate of the model is pretty good, at 93.5%. However, the specificity, or the true negative rate, is not so great, at 18.29%.The precision is 68.24%. The ROC plot indicates our model is not very good at distinguishing false positives from true positives, with an AUC of 62.56%. Overall, this model is not great at determining housing type from tip percentage and time of day. The density plot shows a huge amount of overlap between the predicted log odds for houses and apartments. This kinda makes sense. While I usually notice a trend of tip percentage being better around early rush, sometimes some really drunk people late at night in apartments will tip nicely. Sometimes, people who live in huge houses in nice neighborhoods will tip poorly during our busiest time of the day. It's all about the love of the game, delivering pizzas, rather than counting on rich people to be frivolous with their money and less fortunate people to be stingy. 

---
  
#Logistic Regression Model #2
<br>
This time, I re-ran the logistic regression model with all variables in the data set (that did not overlap in information). Then, after performing Lasso on the regression, I chose the best (most predictive) variables, then Cross Validated the model to make sure the AUC did not indicate overfitting.
<br>
```{r}
#lg for all variables that don't overlap each other
pizza2<- pizza2 %>% na.omit() %>% mutate(y=ifelse(apartment_or_house=="H",1,0)) %>% select(-apartment_or_house)
fit<-glm(y~area+tip_perc+rate+tip_method+hours_worked+position_worked, data=pizza2, family="binomial")

probs1<-predict(fit,type="response")
class_diag(probs1,pizza2$y)

#CV time
k=10

data <- pizza2 %>% sample_frac #put rows of dataset in random order
folds <- ntile(1:nrow(data),n=10) #create fold labels

diags<-NULL
for(i in 1:k){
  train <- data[folds!=i,] #create training set (all but fold i)
  test <- data[folds==i,] #create test set (just fold i)
  truth <- test$y 
  
  fit <- glm(y~area+tip_perc+rate+tip_method+hours_worked+position_worked, data=train, family="binomial")
  probs <- predict(fit, newdata=test, type="response")
  
  diags<-rbind(diags,class_diag(probs,truth))
}

summarize_all(diags,mean)#LOTS of overfitting
```
<br>
Using all the variables to predict housing type, the accuracy was astonishingly high, at 94.91%, along with a great TPR of 97.4%, TNR of 90.24% and an AUC of 99.16%. After running a cross-validation to see how well the data can predict housing type on new variables, the AUC dropped dramatically to 69.66%, as expected, which indicates overfitting. 
<br>
```{r}
#lasso
library(glmnet)
y<-as.matrix(pizza2$y)
x<-model.matrix(y~area+tip_perc+rate+tip_method+hours_worked+position_worked,data=pizza2)[,-1] 

cv <- cv.glmnet(x,y, family="binomial") 

cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)


#cross-validating lasso model
set.seed(1234)
k=10

data <- pizza2 %>% sample_frac 
folds <- ntile(1:nrow(data),n=10)

diags<-NULL
for(i in 1:k){
  train <- data[folds!=i,]
  test <- data[folds==i,] 
  truth <- test$y 
  
  fit <- glm(y~area, 
             data=train, family="binomial")
  probs <- predict(fit, newdata=test, type="response")
  
  diags<-rbind(diags,class_diag(probs,truth))
}

diags%>%summarize_all(mean)


```
<br>

A lasso was performed to indicate which variables are the best at predicting housing type,in which only areas 14,15,16,7, and MAIN were needed to predict housing type. For clarity purposes, I used the whole "area" variable, rather than parsing out the areas into sections. Re-running a CV on the fit model built using the lasso output, the AUC increased to 97.8%, close to the original fit AUC of 99.16%. All other in sample classification diagnostics between original fit and lasso fit were almost identical. 

<br>

I have to admit that this was very disappointing. I was hoping to be able to predict housing type like a pizza wizard off of something more unrelated than area. Most areas are broken into houses vs apartments anyway, so the result is not very suprising. Oh well.

---

#Random Stats

<br>
Which apartment tips the best?

```{r}
#visualizing by stats which apartment tips best percentage-wise

#fixing pizza2 to have apartment or house variable again:
pizza %>% 
  group_by(Date) %>% 
  filter(!is.na(tip)) %>% 
  filter(!is.na(total)) %>% 
  mutate(total_tips=sum(tip)) %>% 
  mutate(rate=(total_tips/hours_worked))->pizza2

pizza2 %>% 
  filter(apartment_or_house=="A") %>% 
  group_by(street_name) %>% 
  filter(!tip_perc>60) %>% #getting rid of the outlier
  summarize(avg_tip_perc=mean(tip_perc)) %>%
  arrange(desc(avg_tip_perc))

  
pizza2 %>%  
  filter(apartment_or_house=="A") %>% 
  group_by(street_name) %>% 
  filter(!tip_perc>60) %>% #getting rid of the outlier
  mutate(avg_tip_perc=mean(tip_perc)) %>% 
  ggplot()+
  geom_jitter(aes(x=1:109,y=tip_perc))+
  geom_jitter(aes(x=20, y=avg_tip_perc), color="red", shape="square")+
  facet_wrap(~street_name)
```

Correlation heat map of all variables
```{r}

#correlation for all numeric variables
pizza_new_area %>% select(-time2) ->pizza_new_area
ggcorr(pizza_new_area, label=TRUE)


#for write-ins at apartments, whats the mean tip_perc?
pizza2 %>% filter(apartment_or_house=="A") %>% filter(tip_method=="write in") %>% group_by(street_name) %>% summarize(mean=mean(tip_perc)) %>% arrange(desc(mean))

#for cash orders at apartments, what's the mean tip_perc?
pizza2 %>% filter(apartment_or_house=="A") %>% filter(tip_method=="cash order") %>% group_by(street_name) %>% summarize(mean=mean(tip_perc)) %>% arrange(desc(mean))

#for all cash orders, whats the mean tip_perc for each day?
pizza2 %>% filter(tip_method=="cash order") %>% summarize(mean=mean(tip_perc)) %>% arrange(desc(mean))
```














